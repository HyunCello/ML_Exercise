{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w1 = 1.0\n",
    "w2 = 2.0\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model forward pass\n",
    "def forward(x):\n",
    "    return x * x * w2 + x * w1 + b\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "# compute gradient\n",
    "def gradient1(x, y):  # d_loss/d_w1\n",
    "    return 2 * x * (x ** 2 + w2 + x * w1 + b - y)\n",
    "\n",
    "def gradient2(x, y):  # d_loss/d_w1\n",
    "    return 2 * x * x * (x ** 2 + w2 + x * w1 + b - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction (before training) 4 -909.7729088957964\n\tgrad1:  1.0 2.0 -146.94\n\tgrad2:  1.0 2.0 -146.94\n\tgrad1:  2.0 4.0 -355.5\n\tgrad2:  2.0 4.0 -710.99\n\tgrad1:  3.0 6.0 -524.65\n\tgrad2:  3.0 6.0 -1573.95\nprogress: 0 w1= -10.54 80471.23\nprogress: 0 w2= -27.34 80471.23\n\tgrad1:  1.0 2.0 -77.76\n\tgrad2:  1.0 2.0 -77.76\n\tgrad1:  2.0 4.0 -184.35\n\tgrad2:  2.0 4.0 -368.71\n\tgrad1:  3.0 6.0 -261.81\n\tgrad2:  3.0 6.0 -785.42\nprogress: 1 w1= -5.3 24676.21\nprogress: 1 w2= -15.02 24676.21\n\tgrad1:  1.0 2.0 -42.64\n\tgrad2:  1.0 2.0 -42.64\n\tgrad1:  2.0 4.0 -97.38\n\tgrad2:  2.0 4.0 -194.76\n\tgrad1:  3.0 6.0 -128.11\n\tgrad2:  3.0 6.0 -384.33\nprogress: 2 w1= -2.62 8665.23\nprogress: 2 w2= -8.8 8665.23\n\tgrad1:  1.0 2.0 -24.85\n\tgrad2:  1.0 2.0 -24.85\n\tgrad1:  2.0 4.0 -53.2\n\tgrad2:  2.0 4.0 -106.39\n\tgrad1:  3.0 6.0 -60.07\n\tgrad2:  3.0 6.0 -180.2\nprogress: 3 w1= -1.24 3710.56\nprogress: 3 w2= -5.69 3710.56\n\tgrad1:  1.0 2.0 -15.86\n\tgrad2:  1.0 2.0 -15.86\n\tgrad1:  2.0 4.0 -30.77\n\tgrad2:  2.0 4.0 -61.54\n\tgrad1:  3.0 6.0 -25.41\n\tgrad2:  3.0 6.0 -76.22\nprogress: 4 w1= -0.52 2018.54\nprogress: 4 w2= -4.15 2018.54\n\tgrad1:  1.0 2.0 -11.34\n\tgrad2:  1.0 2.0 -11.34\n\tgrad1:  2.0 4.0 -19.4\n\tgrad2:  2.0 4.0 -38.8\n\tgrad1:  3.0 6.0 -7.72\n\tgrad2:  3.0 6.0 -23.15\nprogress: 5 w1= -0.13 1382.14\nprogress: 5 w2= -3.42 1382.14\n\tgrad1:  1.0 2.0 -9.11\n\tgrad2:  1.0 2.0 -9.11\n\tgrad1:  2.0 4.0 -13.66\n\tgrad2:  2.0 4.0 -27.32\n\tgrad1:  3.0 6.0 1.34\n\tgrad2:  3.0 6.0 4.03\nprogress: 6 w1= 0.08 1130.23\nprogress: 6 w2= -3.1 1130.23\n\tgrad1:  1.0 2.0 -8.03\n\tgrad2:  1.0 2.0 -8.03\n\tgrad1:  2.0 4.0 -10.78\n\tgrad2:  2.0 4.0 -21.56\n\tgrad1:  3.0 6.0 6.02\n\tgrad2:  3.0 6.0 18.07\nprogress: 7 w1= 0.21 1036.7\nprogress: 7 w2= -2.98 1036.7\n\tgrad1:  1.0 2.0 -7.55\n\tgrad2:  1.0 2.0 -7.55\n\tgrad1:  2.0 4.0 -9.35\n\tgrad2:  2.0 4.0 -18.71\n\tgrad1:  3.0 6.0 8.47\n\tgrad2:  3.0 6.0 25.42\nprogress: 8 w1= 0.29 1015.66\nprogress: 8 w2= -2.97 1015.66\n\tgrad1:  1.0 2.0 -7.36\n\tgrad2:  1.0 2.0 -7.36\n\tgrad1:  2.0 4.0 -8.67\n\tgrad2:  2.0 4.0 -17.34\n\tgrad1:  3.0 6.0 9.79\n\tgrad2:  3.0 6.0 29.37\nprogress: 9 w1= 0.35 1030.57\nprogress: 9 w2= -3.02 1030.57\npredited score (after training) 4 hours of studying:  -46.876516270411024\n"
     ]
    }
   ],
   "source": [
    "# Before  training\n",
    "print(\"Prediction (before training)\", 4, forward(4))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        # Compute derivative w.r.t to the learned weights\n",
    "        # Update the weights\n",
    "        # Compute the loss and print progress\n",
    "        grad1 = gradient1(x_val, y_val)\n",
    "        grad2 = gradient2(x_val, y_val)\n",
    "        w1 = w1 - 0.01 * grad1\n",
    "        w2 = w2 - 0.01 * grad2\n",
    "        print(\"\\tgrad1: \", x_val, y_val, round(grad1, 2))\n",
    "        print(\"\\tgrad2: \", x_val, y_val, round(grad2, 2))\n",
    "        l = loss(x_val, y_val)\n",
    "    print(\"progress:\", epoch, \"w1=\", round(w1, 2), round(l,2))\n",
    "    print(\"progress:\", epoch, \"w2=\", round(w2, 2), round(l,2))\n",
    "\n",
    "# After training\n",
    "print(\"predited score (after training)\", \"4 hours of studying: \", forward(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}