{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w1 = 1.0\n",
    "w2 = 2.0\n",
    "b = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model forward pass\n",
    "def forward(x):\n",
    "    return x * x * w2 + x * w1 + b\n",
    "\n",
    "# Loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)\n",
    "\n",
    "# compute gradient\n",
    "def gradient1(x, y):  # d_loss/d_w1\n",
    "    return 2 * x * (x * x * w2 + x * w1 + b - y)\n",
    "\n",
    "def gradient2(x, y):  # d_loss/d_w1\n",
    "    return 2 * x * x * (x * x * w2 + x * w1 + b - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction (before training) 4 39.0\n\tgrad1:  1.0 2.0 8.0\n\tgrad2:  1.0 2.0 8.0\n\tgrad1:  2.0 4.0 34.08\n\tgrad2:  2.0 4.0 68.16\n\tgrad1:  3.0 6.0 59.3\n\tgrad2:  3.0 6.0 177.9\nprogress: 0 w1= -0.01 62.51\nprogress: 0 w2= -0.54 62.51\n\tgrad1:  1.0 2.0 0.89\n\tgrad2:  1.0 2.0 0.89\n\tgrad1:  2.0 4.0 -12.97\n\tgrad2:  2.0 4.0 -25.95\n\tgrad1:  3.0 6.0 -31.73\n\tgrad2:  3.0 6.0 -95.2\nprogress: 1 w1= 0.42 17.9\nprogress: 1 w2= 0.66 17.9\n\tgrad1:  1.0 2.0 4.17\n\tgrad2:  1.0 2.0 4.17\n\tgrad1:  2.0 4.0 8.99\n\tgrad2:  2.0 4.0 17.97\n\tgrad1:  3.0 6.0 11.06\n\tgrad2:  3.0 6.0 33.18\nprogress: 2 w1= 0.18 2.18\nprogress: 2 w2= 0.11 2.18\n\tgrad1:  1.0 2.0 2.58\n\tgrad2:  1.0 2.0 2.58\n\tgrad1:  2.0 4.0 -1.42\n\tgrad2:  2.0 4.0 -2.84\n\tgrad1:  3.0 6.0 -8.92\n\tgrad2:  3.0 6.0 -26.75\nprogress: 3 w1= 0.26 1.41\nprogress: 3 w2= 0.38 1.41\n\tgrad1:  1.0 2.0 3.28\n\tgrad2:  1.0 2.0 3.28\n\tgrad1:  2.0 4.0 3.35\n\tgrad2:  2.0 4.0 6.71\n\tgrad1:  3.0 6.0 0.55\n\tgrad2:  3.0 6.0 1.65\nprogress: 4 w1= 0.19 0.01\nprogress: 4 w2= 0.26 0.01\n\tgrad1:  1.0 2.0 2.9\n\tgrad2:  1.0 2.0 2.9\n\tgrad1:  2.0 4.0 1.01\n\tgrad2:  2.0 4.0 2.02\n\tgrad1:  3.0 6.0 -3.8\n\tgrad2:  3.0 6.0 -11.39\nprogress: 5 w1= 0.19 0.26\nprogress: 5 w2= 0.33 0.26\n\tgrad1:  1.0 2.0 3.03\n\tgrad2:  1.0 2.0 3.03\n\tgrad1:  2.0 4.0 2.01\n\tgrad2:  2.0 4.0 4.01\n\tgrad1:  3.0 6.0 -1.67\n\tgrad2:  3.0 6.0 -5.01\nprogress: 6 w1= 0.15 0.05\nprogress: 6 w2= 0.31 0.05\n\tgrad1:  1.0 2.0 2.92\n\tgrad2:  1.0 2.0 2.92\n\tgrad1:  2.0 4.0 1.44\n\tgrad2:  2.0 4.0 2.87\n\tgrad1:  3.0 6.0 -2.58\n\tgrad2:  3.0 6.0 -7.73\nprogress: 7 w1= 0.14 0.12\nprogress: 7 w2= 0.33 0.12\n\tgrad1:  1.0 2.0 2.92\n\tgrad2:  1.0 2.0 2.92\n\tgrad1:  2.0 4.0 1.6\n\tgrad2:  2.0 4.0 3.21\n\tgrad1:  3.0 6.0 -2.06\n\tgrad2:  3.0 6.0 -6.19\nprogress: 8 w1= 0.11 0.08\nprogress: 8 w2= 0.33 0.08\n\tgrad1:  1.0 2.0 2.88\n\tgrad2:  1.0 2.0 2.88\n\tgrad1:  2.0 4.0 1.43\n\tgrad2:  2.0 4.0 2.86\n\tgrad1:  3.0 6.0 -2.22\n\tgrad2:  3.0 6.0 -6.66\nprogress: 9 w1= 0.09 0.09\nprogress: 9 w2= 0.34 0.09\n\tgrad1:  1.0 2.0 2.85\n\tgrad2:  1.0 2.0 2.85\n\tgrad1:  2.0 4.0 1.41\n\tgrad2:  2.0 4.0 2.83\n\tgrad1:  3.0 6.0 -2.06\n\tgrad2:  3.0 6.0 -6.18\nprogress: 10 w1= 0.07 0.08\nprogress: 10 w2= 0.34 0.08\n\tgrad1:  1.0 2.0 2.82\n\tgrad2:  1.0 2.0 2.82\n\tgrad1:  2.0 4.0 1.33\n\tgrad2:  2.0 4.0 2.65\n\tgrad1:  3.0 6.0 -2.05\n\tgrad2:  3.0 6.0 -6.15\nprogress: 11 w1= 0.05 0.07\nprogress: 11 w2= 0.35 0.07\n\tgrad1:  1.0 2.0 2.79\n\tgrad2:  1.0 2.0 2.79\n\tgrad1:  2.0 4.0 1.28\n\tgrad2:  2.0 4.0 2.55\n\tgrad1:  3.0 6.0 -1.97\n\tgrad2:  3.0 6.0 -5.92\nprogress: 12 w1= 0.03 0.07\nprogress: 12 w2= 0.35 0.07\n\tgrad1:  1.0 2.0 2.76\n\tgrad2:  1.0 2.0 2.76\n\tgrad1:  2.0 4.0 1.21\n\tgrad2:  2.0 4.0 2.42\n\tgrad1:  3.0 6.0 -1.93\n\tgrad2:  3.0 6.0 -5.79\nprogress: 13 w1= 0.01 0.07\nprogress: 13 w2= 0.36 0.07\n\tgrad1:  1.0 2.0 2.73\n\tgrad2:  1.0 2.0 2.73\n\tgrad1:  2.0 4.0 1.15\n\tgrad2:  2.0 4.0 2.3\n\tgrad1:  3.0 6.0 -1.87\n\tgrad2:  3.0 6.0 -5.62\nprogress: 14 w1= -0.01 0.06\nprogress: 14 w2= 0.37 0.06\n\tgrad1:  1.0 2.0 2.7\n\tgrad2:  1.0 2.0 2.7\n\tgrad1:  2.0 4.0 1.09\n\tgrad2:  2.0 4.0 2.18\n\tgrad1:  3.0 6.0 -1.82\n\tgrad2:  3.0 6.0 -5.47\nprogress: 15 w1= -0.03 0.06\nprogress: 15 w2= 0.37 0.06\n\tgrad1:  1.0 2.0 2.68\n\tgrad2:  1.0 2.0 2.68\n\tgrad1:  2.0 4.0 1.03\n\tgrad2:  2.0 4.0 2.06\n\tgrad1:  3.0 6.0 -1.77\n\tgrad2:  3.0 6.0 -5.31\nprogress: 16 w1= -0.05 0.06\nprogress: 16 w2= 0.38 0.06\n\tgrad1:  1.0 2.0 2.65\n\tgrad2:  1.0 2.0 2.65\n\tgrad1:  2.0 4.0 0.97\n\tgrad2:  2.0 4.0 1.95\n\tgrad1:  3.0 6.0 -1.72\n\tgrad2:  3.0 6.0 -5.16\nprogress: 17 w1= -0.07 0.05\nprogress: 17 w2= 0.38 0.05\n\tgrad1:  1.0 2.0 2.62\n\tgrad2:  1.0 2.0 2.62\n\tgrad1:  2.0 4.0 0.92\n\tgrad2:  2.0 4.0 1.84\n\tgrad1:  3.0 6.0 -1.67\n\tgrad2:  3.0 6.0 -5.01\nprogress: 18 w1= -0.09 0.05\nprogress: 18 w2= 0.39 0.05\n\tgrad1:  1.0 2.0 2.59\n\tgrad2:  1.0 2.0 2.59\n\tgrad1:  2.0 4.0 0.86\n\tgrad2:  2.0 4.0 1.73\n\tgrad1:  3.0 6.0 -1.62\n\tgrad2:  3.0 6.0 -4.86\nprogress: 19 w1= -0.11 0.05\nprogress: 19 w2= 0.39 0.05\npredited score (after training) 4 hours of studying:  8.86355353451169\n"
     ]
    }
   ],
   "source": [
    "# Before  training\n",
    "print(\"Prediction (before training)\", 4, forward(4))\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(20):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        # Compute derivative w.r.t to the learned weights\n",
    "        # Update the weights\n",
    "        # Compute the loss and print progress\n",
    "        grad1 = gradient1(x_val, y_val)\n",
    "        grad2 = gradient2(x_val, y_val)\n",
    "        w1 = w1 - 0.01 * grad1\n",
    "        w2 = w2 - 0.01 * grad2\n",
    "        print(\"\\tgrad1: \", x_val, y_val, round(grad1, 2))\n",
    "        print(\"\\tgrad2: \", x_val, y_val, round(grad2, 2))\n",
    "        l = loss(x_val, y_val)\n",
    "    print(\"progress:\", epoch, \"w1=\", round(w1, 2), round(l,2))\n",
    "    print(\"progress:\", epoch, \"w2=\", round(w2, 2), round(l,2))\n",
    "\n",
    "# After training\n",
    "print(\"predited score (after training)\", \"4 hours of studying: \", forward(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}