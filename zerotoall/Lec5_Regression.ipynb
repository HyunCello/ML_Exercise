{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch Rhythm\n",
    "# 1. Design your model using class with Variables\n",
    "# 2. Construct loss and optimizer (Select from PyTorch API)\n",
    "# 3. Training cycle (forward, backward, update)\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "x_data = tensor([[1.0],[2.0],[3.0]])\n",
    "y_data = tensor([[2.0], [4.0],[6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "        \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "och: 7 | Loss: 0.7959544658660889 \n",
      "Epoch: 8 | Loss: 0.5909121036529541 \n",
      "Epoch: 9 | Loss: 0.4962332844734192 \n",
      "Epoch: 10 | Loss: 0.45073413848876953 \n",
      "Epoch: 11 | Loss: 0.4271761178970337 \n",
      "Epoch: 12 | Loss: 0.41343337297439575 \n",
      "Epoch: 13 | Loss: 0.40410661697387695 \n",
      "Epoch: 14 | Loss: 0.39679205417633057 \n",
      "Epoch: 15 | Loss: 0.3904188275337219 \n",
      "Epoch: 16 | Loss: 0.3845095634460449 \n",
      "Epoch: 17 | Loss: 0.378850519657135 \n",
      "Epoch: 18 | Loss: 0.3733464777469635 \n",
      "Epoch: 19 | Loss: 0.36795443296432495 \n",
      "Epoch: 20 | Loss: 0.3626547157764435 \n",
      "Epoch: 21 | Loss: 0.3574376404285431 \n",
      "Epoch: 22 | Loss: 0.3522982597351074 \n",
      "Epoch: 23 | Loss: 0.347234308719635 \n",
      "Epoch: 24 | Loss: 0.34224337339401245 \n",
      "Epoch: 25 | Loss: 0.3373246192932129 \n",
      "Epoch: 26 | Loss: 0.3324766457080841 \n",
      "Epoch: 27 | Loss: 0.32769840955734253 \n",
      "Epoch: 28 | Loss: 0.3229888677597046 \n",
      "Epoch: 29 | Loss: 0.3183472454547882 \n",
      "Epoch: 30 | Loss: 0.3137720227241516 \n",
      "Epoch: 31 | Loss: 0.30926230549812317 \n",
      "Epoch: 32 | Loss: 0.3048180043697357 \n",
      "Epoch: 33 | Loss: 0.30043715238571167 \n",
      "Epoch: 34 | Loss: 0.29611945152282715 \n",
      "Epoch: 35 | Loss: 0.2918637692928314 \n",
      "Epoch: 36 | Loss: 0.2876690626144409 \n",
      "Epoch: 37 | Loss: 0.28353482484817505 \n",
      "Epoch: 38 | Loss: 0.2794601321220398 \n",
      "Epoch: 39 | Loss: 0.27544382214546204 \n",
      "Epoch: 40 | Loss: 0.2714850902557373 \n",
      "Epoch: 41 | Loss: 0.26758354902267456 \n",
      "Epoch: 42 | Loss: 0.26373791694641113 \n",
      "Epoch: 43 | Loss: 0.2599475681781769 \n",
      "Epoch: 44 | Loss: 0.25621169805526733 \n",
      "Epoch: 45 | Loss: 0.2525295615196228 \n",
      "Epoch: 46 | Loss: 0.2489004135131836 \n",
      "Epoch: 47 | Loss: 0.24532324075698853 \n",
      "Epoch: 48 | Loss: 0.24179764091968536 \n",
      "Epoch: 49 | Loss: 0.238322451710701 \n",
      "Epoch: 50 | Loss: 0.23489758372306824 \n",
      "Epoch: 51 | Loss: 0.23152172565460205 \n",
      "Epoch: 52 | Loss: 0.22819432616233826 \n",
      "Epoch: 53 | Loss: 0.22491466999053955 \n",
      "Epoch: 54 | Loss: 0.22168216109275818 \n",
      "Epoch: 55 | Loss: 0.2184964418411255 \n",
      "Epoch: 56 | Loss: 0.2153562605381012 \n",
      "Epoch: 57 | Loss: 0.21226125955581665 \n",
      "Epoch: 58 | Loss: 0.20921091735363007 \n",
      "Epoch: 59 | Loss: 0.20620401203632355 \n",
      "Epoch: 60 | Loss: 0.20324081182479858 \n",
      "Epoch: 61 | Loss: 0.20031976699829102 \n",
      "Epoch: 62 | Loss: 0.1974407434463501 \n",
      "Epoch: 63 | Loss: 0.1946033090353012 \n",
      "Epoch: 64 | Loss: 0.19180653989315033 \n",
      "Epoch: 65 | Loss: 0.1890498846769333 \n",
      "Epoch: 66 | Loss: 0.1863330453634262 \n",
      "Epoch: 67 | Loss: 0.1836552619934082 \n",
      "Epoch: 68 | Loss: 0.18101567029953003 \n",
      "Epoch: 69 | Loss: 0.17841434478759766 \n",
      "Epoch: 70 | Loss: 0.17584997415542603 \n",
      "Epoch: 71 | Loss: 0.173322856426239 \n",
      "Epoch: 72 | Loss: 0.17083191871643066 \n",
      "Epoch: 73 | Loss: 0.16837690770626068 \n",
      "Epoch: 74 | Loss: 0.1659569889307022 \n",
      "Epoch: 75 | Loss: 0.1635718047618866 \n",
      "Epoch: 76 | Loss: 0.1612209528684616 \n",
      "Epoch: 77 | Loss: 0.15890394151210785 \n",
      "Epoch: 78 | Loss: 0.15662041306495667 \n",
      "Epoch: 79 | Loss: 0.15436941385269165 \n",
      "Epoch: 80 | Loss: 0.15215080976486206 \n",
      "Epoch: 81 | Loss: 0.1499643176794052 \n",
      "Epoch: 82 | Loss: 0.14780907332897186 \n",
      "Epoch: 83 | Loss: 0.14568494260311127 \n",
      "Epoch: 84 | Loss: 0.14359110593795776 \n",
      "Epoch: 85 | Loss: 0.1415276825428009 \n",
      "Epoch: 86 | Loss: 0.13949361443519592 \n",
      "Epoch: 87 | Loss: 0.13748860359191895 \n",
      "Epoch: 88 | Loss: 0.1355127990245819 \n",
      "Epoch: 89 | Loss: 0.13356509804725647 \n",
      "Epoch: 90 | Loss: 0.13164572417736053 \n",
      "Epoch: 91 | Loss: 0.1297537088394165 \n",
      "Epoch: 92 | Loss: 0.12788905203342438 \n",
      "Epoch: 93 | Loss: 0.12605099380016327 \n",
      "Epoch: 94 | Loss: 0.12423939257860184 \n",
      "Epoch: 95 | Loss: 0.12245403975248337 \n",
      "Epoch: 96 | Loss: 0.12069423496723175 \n",
      "Epoch: 97 | Loss: 0.11895960569381714 \n",
      "Epoch: 98 | Loss: 0.11725001782178879 \n",
      "Epoch: 99 | Loss: 0.1155649870634079 \n",
      "Epoch: 100 | Loss: 0.11390392482280731 \n",
      "Epoch: 101 | Loss: 0.11226703226566315 \n",
      "Epoch: 102 | Loss: 0.11065372824668884 \n",
      "Epoch: 103 | Loss: 0.10906335711479187 \n",
      "Epoch: 104 | Loss: 0.10749594867229462 \n",
      "Epoch: 105 | Loss: 0.10595101118087769 \n",
      "Epoch: 106 | Loss: 0.10442841053009033 \n",
      "Epoch: 107 | Loss: 0.10292765498161316 \n",
      "Epoch: 108 | Loss: 0.10144828259944916 \n",
      "Epoch: 109 | Loss: 0.09999052435159683 \n",
      "Epoch: 110 | Loss: 0.09855331480503082 \n",
      "Epoch: 111 | Loss: 0.09713685512542725 \n",
      "Epoch: 112 | Loss: 0.0957408919930458 \n",
      "Epoch: 113 | Loss: 0.09436498582363129 \n",
      "Epoch: 114 | Loss: 0.09300874918699265 \n",
      "Epoch: 115 | Loss: 0.09167218953371048 \n",
      "Epoch: 116 | Loss: 0.09035466611385345 \n",
      "Epoch: 117 | Loss: 0.08905603736639023 \n",
      "Epoch: 118 | Loss: 0.08777634799480438 \n",
      "Epoch: 119 | Loss: 0.08651478588581085 \n",
      "Epoch: 120 | Loss: 0.08527130633592606 \n",
      "Epoch: 121 | Loss: 0.08404599875211716 \n",
      "Epoch: 122 | Loss: 0.08283796906471252 \n",
      "Epoch: 123 | Loss: 0.08164753019809723 \n",
      "Epoch: 124 | Loss: 0.08047417551279068 \n",
      "Epoch: 125 | Loss: 0.07931763678789139 \n",
      "Epoch: 126 | Loss: 0.07817758619785309 \n",
      "Epoch: 127 | Loss: 0.07705413550138474 \n",
      "Epoch: 128 | Loss: 0.07594683766365051 \n",
      "Epoch: 129 | Loss: 0.07485529780387878 \n",
      "Epoch: 130 | Loss: 0.07377956807613373 \n",
      "Epoch: 131 | Loss: 0.07271920144557953 \n",
      "Epoch: 132 | Loss: 0.07167409360408783 \n",
      "Epoch: 133 | Loss: 0.07064405083656311 \n",
      "Epoch: 134 | Loss: 0.06962879002094269 \n",
      "Epoch: 135 | Loss: 0.06862805783748627 \n",
      "Epoch: 136 | Loss: 0.06764181703329086 \n",
      "Epoch: 137 | Loss: 0.06666967272758484 \n",
      "Epoch: 138 | Loss: 0.06571153551340103 \n",
      "Epoch: 139 | Loss: 0.06476718932390213 \n",
      "Epoch: 140 | Loss: 0.06383630633354187 \n",
      "Epoch: 141 | Loss: 0.06291879713535309 \n",
      "Epoch: 142 | Loss: 0.06201464682817459 \n",
      "Epoch: 143 | Loss: 0.06112336367368698 \n",
      "Epoch: 144 | Loss: 0.06024505943059921 \n",
      "Epoch: 145 | Loss: 0.059379082173109055 \n",
      "Epoch: 146 | Loss: 0.05852573737502098 \n",
      "Epoch: 147 | Loss: 0.05768474191427231 \n",
      "Epoch: 148 | Loss: 0.05685579404234886 \n",
      "Epoch: 149 | Loss: 0.05603865534067154 \n",
      "Epoch: 150 | Loss: 0.05523310974240303 \n",
      "Epoch: 151 | Loss: 0.054439395666122437 \n",
      "Epoch: 152 | Loss: 0.05365704372525215 \n",
      "Epoch: 153 | Loss: 0.052885957062244415 \n",
      "Epoch: 154 | Loss: 0.05212591588497162 \n",
      "Epoch: 155 | Loss: 0.05137666314840317 \n",
      "Epoch: 156 | Loss: 0.050638347864151 \n",
      "Epoch: 157 | Loss: 0.049910616129636765 \n",
      "Epoch: 158 | Loss: 0.04919334128499031 \n",
      "Epoch: 159 | Loss: 0.04848632588982582 \n",
      "Epoch: 160 | Loss: 0.04778946191072464 \n",
      "Epoch: 161 | Loss: 0.04710273817181587 \n",
      "Epoch: 162 | Loss: 0.04642563313245773 \n",
      "Epoch: 163 | Loss: 0.04575861990451813 \n",
      "Epoch: 164 | Loss: 0.045100897550582886 \n",
      "Epoch: 165 | Loss: 0.04445278272032738 \n",
      "Epoch: 166 | Loss: 0.043813835829496384 \n",
      "Epoch: 167 | Loss: 0.04318421334028244 \n",
      "Epoch: 168 | Loss: 0.04256362468004227 \n",
      "Epoch: 169 | Loss: 0.041951872408390045 \n",
      "Epoch: 170 | Loss: 0.04134900122880936 \n",
      "Epoch: 171 | Loss: 0.040754664689302444 \n",
      "Epoch: 172 | Loss: 0.040169015526771545 \n",
      "Epoch: 173 | Loss: 0.03959164023399353 \n",
      "Epoch: 174 | Loss: 0.039022669196128845 \n",
      "Epoch: 175 | Loss: 0.038461923599243164 \n",
      "Epoch: 176 | Loss: 0.03790919855237007 \n",
      "Epoch: 177 | Loss: 0.03736431896686554 \n",
      "Epoch: 178 | Loss: 0.03682729974389076 \n",
      "Epoch: 179 | Loss: 0.03629806637763977 \n",
      "Epoch: 180 | Loss: 0.03577648103237152 \n",
      "Epoch: 181 | Loss: 0.03526219353079796 \n",
      "Epoch: 182 | Loss: 0.03475547954440117 \n",
      "Epoch: 183 | Loss: 0.034255899488925934 \n",
      "Epoch: 184 | Loss: 0.033763669431209564 \n",
      "Epoch: 185 | Loss: 0.033278465270996094 \n",
      "Epoch: 186 | Loss: 0.03280019387602806 \n",
      "Epoch: 187 | Loss: 0.03232881426811218 \n",
      "Epoch: 188 | Loss: 0.03186417743563652 \n",
      "Epoch: 189 | Loss: 0.031406283378601074 \n",
      "Epoch: 190 | Loss: 0.03095492720603943 \n",
      "Epoch: 191 | Loss: 0.03051002509891987 \n",
      "Epoch: 192 | Loss: 0.030071578919887543 \n",
      "Epoch: 193 | Loss: 0.029639430344104767 \n",
      "Epoch: 194 | Loss: 0.029213469475507736 \n",
      "Epoch: 195 | Loss: 0.02879355289041996 \n",
      "Epoch: 196 | Loss: 0.028379719704389572 \n",
      "Epoch: 197 | Loss: 0.02797183394432068 \n",
      "Epoch: 198 | Loss: 0.027569890022277832 \n",
      "Epoch: 199 | Loss: 0.027173662558197975 \n",
      "Epoch: 200 | Loss: 0.026783140376210213 \n",
      "Epoch: 201 | Loss: 0.0263981930911541 \n",
      "Epoch: 202 | Loss: 0.02601885423064232 \n",
      "Epoch: 203 | Loss: 0.02564496360719204 \n",
      "Epoch: 204 | Loss: 0.02527640387415886 \n",
      "Epoch: 205 | Loss: 0.024913061410188675 \n",
      "Epoch: 206 | Loss: 0.02455507218837738 \n",
      "Epoch: 207 | Loss: 0.024202100932598114 \n",
      "Epoch: 208 | Loss: 0.023854367434978485 \n",
      "Epoch: 209 | Loss: 0.023511525243520737 \n",
      "Epoch: 210 | Loss: 0.023173633962869644 \n",
      "Epoch: 211 | Loss: 0.022840548306703568 \n",
      "Epoch: 212 | Loss: 0.022512312978506088 \n",
      "Epoch: 213 | Loss: 0.02218875288963318 \n",
      "Epoch: 214 | Loss: 0.021869909018278122 \n",
      "Epoch: 215 | Loss: 0.021555550396442413 \n",
      "Epoch: 216 | Loss: 0.02124582976102829 \n",
      "Epoch: 217 | Loss: 0.02094040811061859 \n",
      "Epoch: 218 | Loss: 0.020639440044760704 \n",
      "Epoch: 219 | Loss: 0.020342931151390076 \n",
      "Epoch: 220 | Loss: 0.020050497725605965 \n",
      "Epoch: 221 | Loss: 0.019762378185987473 \n",
      "Epoch: 222 | Loss: 0.01947833225131035 \n",
      "Epoch: 223 | Loss: 0.01919841207563877 \n",
      "Epoch: 224 | Loss: 0.01892247051000595 \n",
      "Epoch: 225 | Loss: 0.018650535494089127 \n",
      "Epoch: 226 | Loss: 0.018382474780082703 \n",
      "Epoch: 227 | Loss: 0.018118390813469887 \n",
      "Epoch: 228 | Loss: 0.017857979983091354 \n",
      "Epoch: 229 | Loss: 0.017601268365979195 \n",
      "Epoch: 230 | Loss: 0.017348330467939377 \n",
      "Epoch: 231 | Loss: 0.01709894835948944 \n",
      "Epoch: 232 | Loss: 0.016853319481015205 \n",
      "Epoch: 233 | Loss: 0.01661107689142227 \n",
      "Epoch: 234 | Loss: 0.016372323036193848 \n",
      "Epoch: 235 | Loss: 0.016137070953845978 \n",
      "Epoch: 236 | Loss: 0.015905095264315605 \n",
      "Epoch: 237 | Loss: 0.015676533803343773 \n",
      "Epoch: 238 | Loss: 0.015451259911060333 \n",
      "Epoch: 239 | Loss: 0.01522916555404663 \n",
      "Epoch: 240 | Loss: 0.015010281465947628 \n",
      "Epoch: 241 | Loss: 0.014794552698731422 \n",
      "Epoch: 242 | Loss: 0.014581971801817417 \n",
      "Epoch: 243 | Loss: 0.014372449368238449 \n",
      "Epoch: 244 | Loss: 0.014165813103318214 \n",
      "Epoch: 245 | Loss: 0.013962280005216599 \n",
      "Epoch: 246 | Loss: 0.01376159768551588 \n",
      "Epoch: 247 | Loss: 0.013563832268118858 \n",
      "Epoch: 248 | Loss: 0.013368901796638966 \n",
      "Epoch: 249 | Loss: 0.013176791369915009 \n",
      "Epoch: 250 | Loss: 0.012987395748496056 \n",
      "Epoch: 251 | Loss: 0.012800753116607666 \n",
      "Epoch: 252 | Loss: 0.012616780586540699 \n",
      "Epoch: 253 | Loss: 0.012435435317456722 \n",
      "Epoch: 254 | Loss: 0.01225675642490387 \n",
      "Epoch: 255 | Loss: 0.012080628424882889 \n",
      "Epoch: 256 | Loss: 0.011906936764717102 \n",
      "Epoch: 257 | Loss: 0.011735868640244007 \n",
      "Epoch: 258 | Loss: 0.011567171663045883 \n",
      "Epoch: 259 | Loss: 0.01140094269067049 \n",
      "Epoch: 260 | Loss: 0.0112370690330863 \n",
      "Epoch: 261 | Loss: 0.011075569316744804 \n",
      "Epoch: 262 | Loss: 0.010916436091065407 \n",
      "Epoch: 263 | Loss: 0.010759509168565273 \n",
      "Epoch: 264 | Loss: 0.01060494501143694 \n",
      "Epoch: 265 | Loss: 0.010452523827552795 \n",
      "Epoch: 266 | Loss: 0.010302283801138401 \n",
      "Epoch: 267 | Loss: 0.010154245421290398 \n",
      "Epoch: 268 | Loss: 0.010008279234170914 \n",
      "Epoch: 269 | Loss: 0.009864402934908867 \n",
      "Epoch: 270 | Loss: 0.00972266960889101 \n",
      "Epoch: 271 | Loss: 0.009582951664924622 \n",
      "Epoch: 272 | Loss: 0.00944521650671959 \n",
      "Epoch: 273 | Loss: 0.009309517219662666 \n",
      "Epoch: 274 | Loss: 0.009175685234367847 \n",
      "Epoch: 275 | Loss: 0.009043817408382893 \n",
      "Epoch: 276 | Loss: 0.008913831785321236 \n",
      "Epoch: 277 | Loss: 0.008785740472376347 \n",
      "Epoch: 278 | Loss: 0.008659452199935913 \n",
      "Epoch: 279 | Loss: 0.008535046130418777 \n",
      "Epoch: 280 | Loss: 0.008412377908825874 \n",
      "Epoch: 281 | Loss: 0.008291507139801979 \n",
      "Epoch: 282 | Loss: 0.008172299712896347 \n",
      "Epoch: 283 | Loss: 0.00805488508194685 \n",
      "Epoch: 284 | Loss: 0.007939127273857594 \n",
      "Epoch: 285 | Loss: 0.007825035601854324 \n",
      "Epoch: 286 | Loss: 0.007712545804679394 \n",
      "Epoch: 287 | Loss: 0.00760172214359045 \n",
      "Epoch: 288 | Loss: 0.007492491044104099 \n",
      "Epoch: 289 | Loss: 0.007384814787656069 \n",
      "Epoch: 290 | Loss: 0.007278671488165855 \n",
      "Epoch: 291 | Loss: 0.00717404019087553 \n",
      "Epoch: 292 | Loss: 0.007070919964462519 \n",
      "Epoch: 293 | Loss: 0.006969317328184843 \n",
      "Epoch: 294 | Loss: 0.006869173143059015 \n",
      "Epoch: 295 | Loss: 0.006770418956875801 \n",
      "Epoch: 296 | Loss: 0.006673134863376617 \n",
      "Epoch: 297 | Loss: 0.006577228661626577 \n",
      "Epoch: 298 | Loss: 0.006482705008238554 \n",
      "Epoch: 299 | Loss: 0.006389530375599861 \n",
      "Epoch: 300 | Loss: 0.006297717802226543 \n",
      "Epoch: 301 | Loss: 0.0062071881256997585 \n",
      "Epoch: 302 | Loss: 0.0061180321499705315 \n",
      "Epoch: 303 | Loss: 0.006030085496604443 \n",
      "Epoch: 304 | Loss: 0.005943421274423599 \n",
      "Epoch: 305 | Loss: 0.005858015734702349 \n",
      "Epoch: 306 | Loss: 0.005773772485554218 \n",
      "Epoch: 307 | Loss: 0.005690818652510643 \n",
      "Epoch: 308 | Loss: 0.005609039682894945 \n",
      "Epoch: 309 | Loss: 0.0055284625850617886 \n",
      "Epoch: 310 | Loss: 0.005448983516544104 \n",
      "Epoch: 311 | Loss: 0.005370658822357655 \n",
      "Epoch: 312 | Loss: 0.005293502472341061 \n",
      "Epoch: 313 | Loss: 0.005217438098043203 \n",
      "Epoch: 314 | Loss: 0.005142407491803169 \n",
      "Epoch: 315 | Loss: 0.005068528465926647 \n",
      "Epoch: 316 | Loss: 0.004995689727365971 \n",
      "Epoch: 317 | Loss: 0.004923867993056774 \n",
      "Epoch: 318 | Loss: 0.0048531536012887955 \n",
      "Epoch: 319 | Loss: 0.004783352371305227 \n",
      "Epoch: 320 | Loss: 0.004714639857411385 \n",
      "Epoch: 321 | Loss: 0.004646868444979191 \n",
      "Epoch: 322 | Loss: 0.004580071661621332 \n",
      "Epoch: 323 | Loss: 0.0045142704620957375 \n",
      "Epoch: 324 | Loss: 0.004449375439435244 \n",
      "Epoch: 325 | Loss: 0.004385439213365316 \n",
      "Epoch: 326 | Loss: 0.004322455730289221 \n",
      "Epoch: 327 | Loss: 0.0042602913454174995 \n",
      "Epoch: 328 | Loss: 0.004199086222797632 \n",
      "Epoch: 329 | Loss: 0.004138709045946598 \n",
      "Epoch: 330 | Loss: 0.0040792482905089855 \n",
      "Epoch: 331 | Loss: 0.004020630847662687 \n",
      "Epoch: 332 | Loss: 0.00396283995360136 \n",
      "Epoch: 333 | Loss: 0.003905885387212038 \n",
      "Epoch: 334 | Loss: 0.003849772736430168 \n",
      "Epoch: 335 | Loss: 0.003794434480369091 \n",
      "Epoch: 336 | Loss: 0.003739895299077034 \n",
      "Epoch: 337 | Loss: 0.003686153329908848 \n",
      "Epoch: 338 | Loss: 0.003633192740380764 \n",
      "Epoch: 339 | Loss: 0.003580966964364052 \n",
      "Epoch: 340 | Loss: 0.0035294960252940655 \n",
      "Epoch: 341 | Loss: 0.0034787743352353573 \n",
      "Epoch: 342 | Loss: 0.0034287809394299984 \n",
      "Epoch: 343 | Loss: 0.0033795181661844254 \n",
      "Epoch: 344 | Loss: 0.0033309198915958405 \n",
      "Epoch: 345 | Loss: 0.00328304385766387 \n",
      "Epoch: 346 | Loss: 0.003235861426219344 \n",
      "Epoch: 347 | Loss: 0.0031893718987703323 \n",
      "Epoch: 348 | Loss: 0.003143525216728449 \n",
      "Epoch: 349 | Loss: 0.0030983537435531616 \n",
      "Epoch: 350 | Loss: 0.0030538239516317844 \n",
      "Epoch: 351 | Loss: 0.0030099479481577873 \n",
      "Epoch: 352 | Loss: 0.0029666717164218426 \n",
      "Epoch: 353 | Loss: 0.0029240387957543135 \n",
      "Epoch: 354 | Loss: 0.0028820140287280083 \n",
      "Epoch: 355 | Loss: 0.002840593922883272 \n",
      "Epoch: 356 | Loss: 0.002799759851768613 \n",
      "Epoch: 357 | Loss: 0.002759533002972603 \n",
      "Epoch: 358 | Loss: 0.002719864249229431 \n",
      "Epoch: 359 | Loss: 0.002680780366063118 \n",
      "Epoch: 360 | Loss: 0.002642248757183552 \n",
      "Epoch: 361 | Loss: 0.002604280598461628 \n",
      "Epoch: 362 | Loss: 0.002566858194768429 \n",
      "Epoch: 363 | Loss: 0.0025299612898379564 \n",
      "Epoch: 364 | Loss: 0.002493618754670024 \n",
      "Epoch: 365 | Loss: 0.0024577786680310965 \n",
      "Epoch: 366 | Loss: 0.002422452438622713 \n",
      "Epoch: 367 | Loss: 0.0023876377381384373 \n",
      "Epoch: 368 | Loss: 0.002353320363909006 \n",
      "Epoch: 369 | Loss: 0.0023194896057248116 \n",
      "Epoch: 370 | Loss: 0.0022861675824970007 \n",
      "Epoch: 371 | Loss: 0.0022532911971211433 \n",
      "Epoch: 372 | Loss: 0.002220926806330681 \n",
      "Epoch: 373 | Loss: 0.0021890224888920784 \n",
      "Epoch: 374 | Loss: 0.0021575430873781443 \n",
      "Epoch: 375 | Loss: 0.002126530511304736 \n",
      "Epoch: 376 | Loss: 0.002095987321808934 \n",
      "Epoch: 377 | Loss: 0.0020658369176089764 \n",
      "Epoch: 378 | Loss: 0.002036169869825244 \n",
      "Epoch: 379 | Loss: 0.0020068995654582977 \n",
      "Epoch: 380 | Loss: 0.001978061394765973 \n",
      "Epoch: 381 | Loss: 0.0019496242748573422 \n",
      "Epoch: 382 | Loss: 0.00192161463201046 \n",
      "Epoch: 383 | Loss: 0.0018940051086246967 \n",
      "Epoch: 384 | Loss: 0.001866781385615468 \n",
      "Epoch: 385 | Loss: 0.001839939272031188 \n",
      "Epoch: 386 | Loss: 0.0018135118298232555 \n",
      "Epoch: 387 | Loss: 0.0017874428303912282 \n",
      "Epoch: 388 | Loss: 0.0017617649864405394 \n",
      "Epoch: 389 | Loss: 0.0017364158993586898 \n",
      "Epoch: 390 | Loss: 0.001711481367237866 \n",
      "Epoch: 391 | Loss: 0.0016868705861270428 \n",
      "Epoch: 392 | Loss: 0.0016626514261588454 \n",
      "Epoch: 393 | Loss: 0.0016387320356443524 \n",
      "Epoch: 394 | Loss: 0.001615196350030601 \n",
      "Epoch: 395 | Loss: 0.001591988606378436 \n",
      "Epoch: 396 | Loss: 0.00156910321675241 \n",
      "Epoch: 397 | Loss: 0.0015465503092855215 \n",
      "Epoch: 398 | Loss: 0.001524314982816577 \n",
      "Epoch: 399 | Loss: 0.0015024098102003336 \n",
      "Epoch: 400 | Loss: 0.0014808266423642635 \n",
      "Epoch: 401 | Loss: 0.0014595326501876116 \n",
      "Epoch: 402 | Loss: 0.0014385826652869582 \n",
      "Epoch: 403 | Loss: 0.001417893567122519 \n",
      "Epoch: 404 | Loss: 0.0013975107576698065 \n",
      "Epoch: 405 | Loss: 0.0013774244580417871 \n",
      "Epoch: 406 | Loss: 0.0013576506171375513 \n",
      "Epoch: 407 | Loss: 0.001338109141215682 \n",
      "Epoch: 408 | Loss: 0.0013188972370699048 \n",
      "Epoch: 409 | Loss: 0.0012999542523175478 \n",
      "Epoch: 410 | Loss: 0.0012812690110877156 \n",
      "Epoch: 411 | Loss: 0.0012628285912796855 \n",
      "Epoch: 412 | Loss: 0.0012447042390704155 \n",
      "Epoch: 413 | Loss: 0.0012268004938960075 \n",
      "Epoch: 414 | Loss: 0.001209182315506041 \n",
      "Epoch: 415 | Loss: 0.001191793940961361 \n",
      "Epoch: 416 | Loss: 0.0011746648233383894 \n",
      "Epoch: 417 | Loss: 0.001157780410721898 \n",
      "Epoch: 418 | Loss: 0.0011411500163376331 \n",
      "Epoch: 419 | Loss: 0.0011247529182583094 \n",
      "Epoch: 420 | Loss: 0.0011085924925282598 \n",
      "Epoch: 421 | Loss: 0.0010926510440185666 \n",
      "Epoch: 422 | Loss: 0.0010769413784146309 \n",
      "Epoch: 423 | Loss: 0.0010614836355671287 \n",
      "Epoch: 424 | Loss: 0.0010462035425007343 \n",
      "Epoch: 425 | Loss: 0.001031181775033474 \n",
      "Epoch: 426 | Loss: 0.0010163612896576524 \n",
      "Epoch: 427 | Loss: 0.001001741853542626 \n",
      "Epoch: 428 | Loss: 0.0009873580420389771 \n",
      "Epoch: 429 | Loss: 0.0009731691097840667 \n",
      "Epoch: 430 | Loss: 0.0009591745329089463 \n",
      "Epoch: 431 | Loss: 0.0009453904931433499 \n",
      "Epoch: 432 | Loss: 0.0009318019729107618 \n",
      "Epoch: 433 | Loss: 0.0009184122318401933 \n",
      "Epoch: 434 | Loss: 0.0009052262175828218 \n",
      "Epoch: 435 | Loss: 0.0008922014385461807 \n",
      "Epoch: 436 | Loss: 0.0008793901070021093 \n",
      "Epoch: 437 | Loss: 0.0008667535148561001 \n",
      "Epoch: 438 | Loss: 0.0008542916621081531 \n",
      "Epoch: 439 | Loss: 0.0008420163067057729 \n",
      "Epoch: 440 | Loss: 0.0008299034088850021 \n",
      "Epoch: 441 | Loss: 0.0008179713622666895 \n",
      "Epoch: 442 | Loss: 0.0008062297711148858 \n",
      "Epoch: 443 | Loss: 0.000794628809671849 \n",
      "Epoch: 444 | Loss: 0.0007832144037820399 \n",
      "Epoch: 445 | Loss: 0.0007719617569819093 \n",
      "Epoch: 446 | Loss: 0.0007608674350194633 \n",
      "Epoch: 447 | Loss: 0.0007499426719732583 \n",
      "Epoch: 448 | Loss: 0.0007391521940007806 \n",
      "Epoch: 449 | Loss: 0.000728537212125957 \n",
      "Epoch: 450 | Loss: 0.0007180660031735897 \n",
      "Epoch: 451 | Loss: 0.0007077417685650289 \n",
      "Epoch: 452 | Loss: 0.0006975706201046705 \n",
      "Epoch: 453 | Loss: 0.0006875554099678993 \n",
      "Epoch: 454 | Loss: 0.0006776670343242586 \n",
      "Epoch: 455 | Loss: 0.0006679299985989928 \n",
      "Epoch: 456 | Loss: 0.0006583320791833103 \n",
      "Epoch: 457 | Loss: 0.0006488673388957977 \n",
      "Epoch: 458 | Loss: 0.0006395474774762988 \n",
      "Epoch: 459 | Loss: 0.0006303519476205111 \n",
      "Epoch: 460 | Loss: 0.0006212883163243532 \n",
      "Epoch: 461 | Loss: 0.00061237090267241 \n",
      "Epoch: 462 | Loss: 0.0006035564583726227 \n",
      "Epoch: 463 | Loss: 0.0005948995240032673 \n",
      "Epoch: 464 | Loss: 0.000586333277169615 \n",
      "Epoch: 465 | Loss: 0.0005779158673249185 \n",
      "Epoch: 466 | Loss: 0.0005696203443221748 \n",
      "Epoch: 467 | Loss: 0.0005614274414256215 \n",
      "Epoch: 468 | Loss: 0.0005533527582883835 \n",
      "Epoch: 469 | Loss: 0.0005453922785818577 \n",
      "Epoch: 470 | Loss: 0.000537566258572042 \n",
      "Epoch: 471 | Loss: 0.0005298275500535965 \n",
      "Epoch: 472 | Loss: 0.0005222207400947809 \n",
      "Epoch: 473 | Loss: 0.0005147230112925172 \n",
      "Epoch: 474 | Loss: 0.0005073292413726449 \n",
      "Epoch: 475 | Loss: 0.0005000227829441428 \n",
      "Epoch: 476 | Loss: 0.000492849329020828 \n",
      "Epoch: 477 | Loss: 0.00048575850087217987 \n",
      "Epoch: 478 | Loss: 0.0004787839425262064 \n",
      "Epoch: 479 | Loss: 0.0004718951531685889 \n",
      "Epoch: 480 | Loss: 0.00046511521213687956 \n",
      "Epoch: 481 | Loss: 0.00045842916006222367 \n",
      "Epoch: 482 | Loss: 0.00045184959890320897 \n",
      "Epoch: 483 | Loss: 0.0004453519359230995 \n",
      "Epoch: 484 | Loss: 0.00043894522241316736 \n",
      "Epoch: 485 | Loss: 0.00043264174018986523 \n",
      "Epoch: 486 | Loss: 0.0004264306917320937 \n",
      "Epoch: 487 | Loss: 0.00042028597090393305 \n",
      "Epoch: 488 | Loss: 0.0004142533289268613 \n",
      "Epoch: 489 | Loss: 0.0004082948435097933 \n",
      "Epoch: 490 | Loss: 0.00040243432158604264 \n",
      "Epoch: 491 | Loss: 0.0003966509539168328 \n",
      "Epoch: 492 | Loss: 0.0003909438964910805 \n",
      "Epoch: 493 | Loss: 0.0003853284288197756 \n",
      "Epoch: 494 | Loss: 0.0003797852841671556 \n",
      "Epoch: 495 | Loss: 0.00037432622048072517 \n",
      "Epoch: 496 | Loss: 0.0003689501900225878 \n",
      "Epoch: 497 | Loss: 0.00036364299012348056 \n",
      "Epoch: 498 | Loss: 0.000358428165782243 \n",
      "Epoch: 499 | Loss: 0.00035327073419466615 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    # 1) Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # 2) Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(f'Epoch: {epoch} | Loss: {loss.item()} ')\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction (after training) 4 7.9783935546875\n"
     ]
    }
   ],
   "source": [
    "hour_var = tensor([[4.0]])\n",
    "y_pred = model(hour_var)\n",
    "print(\"Prediction (after training)\",  4, model(hour_var).data[0][0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}